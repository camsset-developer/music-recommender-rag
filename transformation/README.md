# ğŸ”„ Transformation Pipeline

Pipeline de transformaciÃ³n y limpieza de datos para el Music Recommender System.

## ğŸ“‹ DescripciÃ³n

Este mÃ³dulo se encarga de:
1. âœ… Extraer datos raw desde BigQuery
2. ğŸ§¹ Limpiar y normalizar datos (texto y numÃ©ricos)
3. ğŸµ Generar features musicales
4. âœ”ï¸ Validar calidad de datos
5. ğŸ’¾ Guardar datos procesados en BigQuery

## ğŸ“ Estructura

```
transformation/
â”œâ”€â”€ config.py                      # ConfiguraciÃ³n del pipeline
â”œâ”€â”€ main.py                        # Orquestador principal
â”œâ”€â”€ cleaners/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_cleaner.py           # Clase base para cleaners
â”‚   â”œâ”€â”€ text_cleaner.py           # Limpieza de texto
â”‚   â””â”€â”€ numeric_cleaner.py        # Limpieza de datos numÃ©ricos
â”œâ”€â”€ feature_engineering/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_feature.py           # Clase base para features
â”‚   â”œâ”€â”€ text_features.py          # Features de texto
â”‚   â””â”€â”€ music_features.py         # Features musicales
â””â”€â”€ requirements.txt
```

## ğŸš€ Uso

### 1. Instalar dependencias

```bash
cd transformation
pip install -r requirements.txt
```

### 2. Configurar variables de entorno

```bash
# .env
GCP_PROJECT_ID=music-recommender-dev
DATASET_RAW=raw
DATASET_CLEAN=clean
LOG_LEVEL=INFO
```

### 3. Ejecutar el pipeline

```bash
python main.py
```

## ğŸ“Š Proceso de TransformaciÃ³n

### Fase 1: ExtracciÃ³n
- Lee datos desde `{project}.raw.tracks_unified`
- Valida estructura de datos

### Fase 2: Limpieza
- **Texto**: NormalizaciÃ³n, eliminaciÃ³n de espacios extra
- **NumÃ©ricos**: Manejo de valores faltantes, detecciÃ³n de outliers
- **Fechas**: ConversiÃ³n y validaciÃ³n

### Fase 3: Feature Engineering
- **Popularidad**: NormalizaciÃ³n, bins, clasificaciÃ³n
- **DuraciÃ³n**: ConversiÃ³n a segundos/minutos, categorÃ­as
- **Temporal**: AÃ±o, dÃ©cada, era musical, antigÃ¼edad
- **Last.fm**: Playcount (log), tags, tracks similares

### Fase 4: ValidaciÃ³n
- Completitud de campos requeridos
- Tasa de duplicados
- Rango de valores vÃ¡lidos

### Fase 5: Almacenamiento
- Guarda en `{project}.clean.tracks_clean`
- Guarda en `{project}.clean.tracks_features`

## ğŸ¯ Features Generados

### Popularidad
- `popularity_normalized`: 0-1
- `popularity_bin`: very_low, low, medium, high, very_high
- `is_popular`: 1 si popularity >= 60

### DuraciÃ³n
- `duration_seconds`, `duration_minutes`
- `duration_category`: very_short, short, medium, long, very_long
- `is_short_track`, `is_long_track`

### Temporales
- `release_year`, `release_month`, `release_day`
- `release_decade`: 1990s, 2000s, etc.
- `music_era`: 2020s, 2010s, 2000s, 90s, older
- `track_age_years`
- `is_recent_release`

### Last.fm
- `lastfm_playcount`, `lastfm_playcount_log`
- `lastfm_num_tags`, `lastfm_num_similar`
- `lastfm_tag_1`, `lastfm_tag_2`, `lastfm_tag_3`

## âš™ï¸ ConfiguraciÃ³n

Edita `config.py` para ajustar:
- Umbrales de limpieza
- Features a generar
- Validaciones de calidad
- ParÃ¡metros de normalizaciÃ³n

## ğŸ“ˆ MÃ©tricas

El pipeline reporta:
- Registros procesados vs. eliminados
- Tasa de retenciÃ³n
- Campos faltantes rellenados
- Outliers detectados
- Features generados

## ğŸ” ValidaciÃ³n de Calidad

Umbrales por defecto:
- Min. completitud: 70%
- Max. duplicados: 5%
- Min. fechas vÃ¡lidas: 90%

## ğŸ› Troubleshooting

### Error: "No hay datos para procesar"
- Verifica que existan datos en `{project}.raw.tracks_unified`
- Ejecuta primero el pipeline de ingesta

### Error: "Dataset no existe"
- El pipeline crea automÃ¡ticamente el dataset `clean`
- Verifica permisos en GCP

### Warning: "No cumplen estÃ¡ndares de calidad"
- Revisa los logs para ver quÃ© validaciÃ³n fallÃ³
- Ajusta umbrales en `config.py` si es necesario

## ğŸ“ Logs

Los logs incluyen:
- Fase del pipeline
- Registros procesados
- Features generados
- Errores y warnings
- EstadÃ­sticas finales

## ğŸ”— Enlaces

- BigQuery Console: https://console.cloud.google.com/bigquery?project=music-recommender-dev